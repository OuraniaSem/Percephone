{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-03T13:45:59.405512Z",
     "start_time": "2024-07-03T13:45:59.389080Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cebra.data\n",
    "import cebra.datasets\n",
    "import cebra.integrations\n",
    "from cebra import CEBRA\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from percephone.analysis.utils import get_zscore\n",
    "from percephone.cebra.CEBRA_trials_viz import get_recs_dict\n",
    "%matplotlib notebook"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T12:33:40.734239Z",
     "start_time": "2024-07-03T12:33:18.063108Z"
    }
   },
   "cell_type": "code",
   "source": "recs = get_recs_dict(\"Célien\")",
   "id": "68bea29a6ffc0fbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220710_4445_00_synchro20220715_4456_00_synchro\n",
      "20220930_4745_01_synchro\n",
      "\n",
      "20220930_4756_01_synchro\n",
      "20221004_4754_01_synchro\n",
      "20221205_4939_04_synchro\n",
      "20231008_5890_03_synchro\n",
      "20231009_5886_00_synchro\n",
      "20231009_5896_04_synchro\n",
      "20231025_5893_00_synchro\n",
      "20231031_5879_00_synchro\n",
      "20231102_5889_03_synchro\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "20231104_5873_04_synchro\n",
      "Behavioural information already incorporated in the analog.\n",
      "20231104_5881_00_synchro\n",
      "20240404_6606_02_synchro\n",
      "20240405_6601_02_synchro\n",
      "20240408_6609_00_synchro\n",
      "20240425_6611_00_synchro\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n",
      "Behavioural information already incorporated in the analog.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T13:46:04.495444Z",
     "start_time": "2024-07-03T13:46:04.351803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hypo_only = False\n",
    "\n",
    "names_wt, datas_wt, labels_wt = [], [], []\n",
    "names_ko, datas_ko, labels_ko = [], [], []\n",
    "\n",
    "for rec in recs.values():\n",
    "    if not (rec.genotype == \"KO\" and hypo_only):\n",
    "        name = rec.filename\n",
    "        label = rec.detected_stim.astype(int)\n",
    "        data = get_zscore(rec, exc_neurons=True, inh_neurons=True, time_span=\"stim\", window=0.5, estimator=\"Mean\", sort=False, amp_sort=False, single_frame_estimator=True)[0].T\n",
    "        \n",
    "        if rec.genotype == \"WT\":\n",
    "            names_wt.append(name)\n",
    "            datas_wt.append(data)\n",
    "            labels_wt.append(label)\n",
    "        else:\n",
    "            names_ko.append(name)\n",
    "            datas_ko.append(data)\n",
    "            labels_ko.append(label)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(f\"WT: {names_wt}\")\n",
    "print(f\"KO: {names_ko}\")"
   ],
   "id": "4b5f639d250ec8a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT: [4456, 4745, 4939, 5886, 5896, 5879, 5889, 5873, 6606]\n",
      "KO: [4445, 4756, 4754, 5890, 5893, 5881, 6601, 6609, 6611]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Single-animal model",
   "id": "138d92f77a246026"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:08:39.150536Z",
     "start_time": "2024-07-03T14:04:04.504952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_iter=1000\n",
    "\n",
    "embeddings_wt = dict()\n",
    "embeddings_ko = dict()\n",
    "\n",
    "# Single session training\n",
    "for name, X, y in zip(names_wt, datas_wt, labels_wt):\n",
    "    # Fit one CEBRA model per session (i.e., per rat)\n",
    "    print(f\"Fitting CEBRA for {name}\")\n",
    "    cebra_model = CEBRA(model_architecture='offset10-model',\n",
    "                        batch_size=512,\n",
    "                        learning_rate=3e-4,\n",
    "                        temperature=1,\n",
    "                        output_dimension=3,\n",
    "                        max_iterations=max_iter,\n",
    "                        distance='cosine',\n",
    "                        conditional='time_delta',\n",
    "                        device='cuda_if_available',\n",
    "                        verbose=True,\n",
    "                        time_offsets=10)\n",
    "\n",
    "    cebra_model.fit(X, y)\n",
    "    embeddings_wt[name] = cebra_model.transform(X)\n",
    "for name, X, y in zip(names_ko, datas_ko, labels_ko):\n",
    "    # Fit one CEBRA model per session (i.e., per rat)\n",
    "    print(f\"Fitting CEBRA for {name}\")\n",
    "    cebra_model = CEBRA(model_architecture='offset10-model',\n",
    "                        batch_size=512,\n",
    "                        learning_rate=3e-4,\n",
    "                        temperature=1,\n",
    "                        output_dimension=3,\n",
    "                        max_iterations=max_iter,\n",
    "                        distance='cosine',\n",
    "                        conditional='time_delta',\n",
    "                        device='cuda_if_available',\n",
    "                        verbose=True,\n",
    "                        time_offsets=10)\n",
    "\n",
    "    cebra_model.fit(X, y)\n",
    "    embeddings_ko[name] = cebra_model.transform(X)\n",
    "\n",
    "\n",
    "# Align the single session embeddings to the first rat\n",
    "alignment = cebra.data.helper.OrthogonalProcrustesAlignment()\n",
    "first_rat_wt = list(embeddings_wt.keys())[0]\n",
    "first_rat_ko = list(embeddings_ko.keys())[0]\n",
    "\n",
    "for j, rat_name in enumerate(list(embeddings_wt.keys())[1:]):\n",
    "    embeddings_wt[f\"{rat_name}\"] = alignment.fit_transform(\n",
    "        embeddings_wt[first_rat_wt], embeddings_wt[rat_name], labels_wt[0], labels_wt[j+1])\n",
    "for j, rat_name in enumerate(list(embeddings_ko.keys())[1:]):\n",
    "    embeddings_ko[f\"{rat_name}\"] = alignment.fit_transform(\n",
    "        embeddings_ko[first_rat_ko], embeddings_ko[rat_name], labels_ko[0], labels_ko[j+1])\n",
    "\n",
    "# Save embeddings in current folder\n",
    "# with open('embeddings_wt.pkl', 'wb') as f:\n",
    "#     pickle.dump(embeddings_wt, f)\n",
    "# with open('embeddings_ko.pkl', 'wb') as f:\n",
    "#     pickle.dump(embeddings_ko, f)\n"
   ],
   "id": "4fb8292a3d2a2736",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 4456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.7998 neg:  6.6749 total:  5.8751 temperature:  1.0000: 100%|██████████| 1000/1000 [00:17<00:00, 58.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 4745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.7580 neg:  6.6270 total:  5.8690 temperature:  1.0000: 100%|██████████| 1000/1000 [00:16<00:00, 61.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 4939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.6837 neg:  6.6170 total:  5.9332 temperature:  1.0000: 100%|██████████| 1000/1000 [00:15<00:00, 64.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8402 neg:  6.7900 total:  5.9497 temperature:  1.0000: 100%|██████████| 1000/1000 [00:15<00:00, 64.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8510 neg:  6.6325 total:  5.7815 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 68.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8553 neg:  6.6885 total:  5.8332 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 68.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8731 neg:  6.8808 total:  6.0077 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 68.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.7052 neg:  6.7426 total:  6.0374 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 66.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.7072 neg:  6.6515 total:  5.9443 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 67.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 4445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.9207 neg:  6.8184 total:  5.8977 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 66.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 4756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8954 neg:  6.9122 total:  6.0168 temperature:  1.0000: 100%|██████████| 1000/1000 [00:15<00:00, 65.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 4754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8179 neg:  6.7462 total:  5.9283 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 67.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8558 neg:  6.6865 total:  5.8307 temperature:  1.0000: 100%|██████████| 1000/1000 [00:15<00:00, 66.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8805 neg:  6.6454 total:  5.7649 temperature:  1.0000: 100%|██████████| 1000/1000 [00:15<00:00, 64.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.7257 neg:  6.6307 total:  5.9050 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 68.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8599 neg:  6.6439 total:  5.7840 temperature:  1.0000: 100%|██████████| 1000/1000 [00:14<00:00, 66.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8747 neg:  6.9797 total:  6.1050 temperature:  1.0000: 100%|██████████| 1000/1000 [00:15<00:00, 65.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CEBRA for 6611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos: -0.8759 neg:  6.9388 total:  6.0629 temperature:  1.0000: 100%|██████████| 1000/1000 [00:15<00:00, 66.35it/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-animal models",
   "id": "38d54a4879d5d648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-03T14:09:58.799465Z",
     "start_time": "2024-07-03T14:09:58.652238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "multi_embeddings_wt = dict()\n",
    "multi_embeddings_ko = dict()\n",
    "\n",
    "# Multisession training\n",
    "multi_cebra_model_wt = CEBRA(model_architecture='offset10-model',\n",
    "                    batch_size=512,\n",
    "                    learning_rate=3e-4,\n",
    "                    temperature=1,\n",
    "                    output_dimension=3,\n",
    "                    max_iterations=max_iter,\n",
    "                    distance='cosine',\n",
    "                    conditional='time_delta',\n",
    "                    device='cuda_if_available',\n",
    "                    verbose=True,\n",
    "                    time_offsets=10)\n",
    "multi_cebra_model_ko = CEBRA(model_architecture='offset10-model',\n",
    "                    batch_size=512,\n",
    "                    learning_rate=3e-4,\n",
    "                    temperature=1,\n",
    "                    output_dimension=3,\n",
    "                    max_iterations=max_iter,\n",
    "                    distance='cosine',\n",
    "                    conditional='time_delta',\n",
    "                    device='cuda_if_available',\n",
    "                    verbose=True,\n",
    "                    time_offsets=10)\n",
    "\n",
    "# Provide a list of data, i.e. datas = [data_a, data_b, ...]\n",
    "multi_cebra_model_wt.fit(datas_wt, labels_wt)\n",
    "multi_cebra_model_ko.fit(datas_wt, labels_wt)\n",
    "\n",
    "# Transform each session with the right model, by providing the corresponding session ID\n",
    "for i, (name, X) in enumerate(zip(names_wt, datas_wt)):\n",
    "    multi_embeddings_wt[name] = multi_cebra_model_wt.transform(X, session_id=i)\n",
    "for i, (name, X) in enumerate(zip(names_ko, datas_ko)):\n",
    "    multi_embeddings_ko[name] = multi_cebra_model_ko.transform(X, session_id=i)\n",
    "\n",
    "# Save embeddings in current folder\n",
    "with open('multi_embeddings_wt.pkl', 'wb') as f:\n",
    "    pickle.dump(multi_embeddings_wt, f)\n",
    "with open('multi_embeddings_ko.pkl', 'wb') as f:\n",
    "    pickle.dump(multi_embeddings_ko, f)"
   ],
   "id": "1fa356a666e123a8",
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Multisession implementation does not support discrete index yet.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 29\u001B[0m\n\u001B[0;32m     16\u001B[0m multi_cebra_model_ko \u001B[38;5;241m=\u001B[39m CEBRA(model_architecture\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moffset10-model\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     17\u001B[0m                     batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m512\u001B[39m,\n\u001B[0;32m     18\u001B[0m                     learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3e-4\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m                     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     26\u001B[0m                     time_offsets\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Provide a list of data, i.e. datas = [data_a, data_b, ...]\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m \u001B[43mmulti_cebra_model_wt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatas_wt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels_wt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m multi_cebra_model_ko\u001B[38;5;241m.\u001B[39mfit(datas_wt, labels_wt)\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# Transform each session with the right model, by providing the corresponding session ID\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Percephone\\venv\\Lib\\site-packages\\cebra\\integrations\\sklearn\\cebra.py:1193\u001B[0m, in \u001B[0;36mCEBRA.fit\u001B[1;34m(self, X, adapt, callback, callback_frequency, *y)\u001B[0m\n\u001B[0;32m   1188\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapt_fit(X,\n\u001B[0;32m   1189\u001B[0m                     \u001B[38;5;241m*\u001B[39my,\n\u001B[0;32m   1190\u001B[0m                     callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m   1191\u001B[0m                     callback_frequency\u001B[38;5;241m=\u001B[39mcallback_frequency)\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1193\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpartial_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1194\u001B[0m \u001B[43m                     \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1195\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1196\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mcallback_frequency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_frequency\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1197\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_\n\u001B[0;32m   1199\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Percephone\\venv\\Lib\\site-packages\\cebra\\integrations\\sklearn\\cebra.py:1098\u001B[0m, in \u001B[0;36mCEBRA.partial_fit\u001B[1;34m(self, X, callback, callback_frequency, *y)\u001B[0m\n\u001B[0;32m   1066\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Partially fit the estimator to the given dataset.\u001B[39;00m\n\u001B[0;32m   1067\u001B[0m \n\u001B[0;32m   1068\u001B[0m \u001B[38;5;124;03mIt is useful when the whole dataset is too big to fit in memory at once.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1095\u001B[0m \n\u001B[0;32m   1096\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1097\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1098\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_partial_fit(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate_,\n\u001B[0;32m   1100\u001B[0m                   callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m   1101\u001B[0m                   callback_frequency\u001B[38;5;241m=\u001B[39mcallback_frequency)\n\u001B[0;32m   1102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Percephone\\venv\\Lib\\site-packages\\cebra\\integrations\\sklearn\\cebra.py:886\u001B[0m, in \u001B[0;36mCEBRA._prepare_fit\u001B[1;34m(self, X, *y)\u001B[0m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice_ \u001B[38;5;241m=\u001B[39m sklearn_utils\u001B[38;5;241m.\u001B[39mcheck_device(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m    885\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moffset_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_offset()\n\u001B[1;32m--> 886\u001B[0m dataset, is_multisession \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    888\u001B[0m loader, solver_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_loader(\n\u001B[0;32m    889\u001B[0m     dataset,\n\u001B[0;32m    890\u001B[0m     max_iterations\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iterations,\n\u001B[0;32m    891\u001B[0m     is_multisession\u001B[38;5;241m=\u001B[39mis_multisession)\n\u001B[0;32m    892\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_model(dataset, is_multisession)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Percephone\\venv\\Lib\\site-packages\\cebra\\integrations\\sklearn\\cebra.py:647\u001B[0m, in \u001B[0;36mCEBRA._prepare_data\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    644\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, \u001B[38;5;28mlist\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X[\u001B[38;5;241m0\u001B[39m], Iterable) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\n\u001B[0;32m    645\u001B[0m         X[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[0;32m    646\u001B[0m     is_multisession \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 647\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43m_get_dataset_multi\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    649\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _are_sessions_equal(X, y):\n",
      "File \u001B[1;32m~\\PycharmProjects\\Percephone\\venv\\Lib\\site-packages\\cebra\\integrations\\sklearn\\cebra.py:638\u001B[0m, in \u001B[0;36mCEBRA._prepare_data.<locals>._get_dataset_multi\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m    632\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(X[session]) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(y[labels][session]):\n\u001B[0;32m    633\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    634\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid number of samples in session \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msession\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for set of label \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    635\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(X[session])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, while y has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(y[labels][session])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    636\u001B[0m             )\n\u001B[1;32m--> 638\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcebra\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDatasetCollection\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m    639\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_get_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43my_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    640\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mX_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_session\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    641\u001B[0m \u001B[43m\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Percephone\\venv\\Lib\\site-packages\\cebra\\data\\datasets.py:225\u001B[0m, in \u001B[0;36mDatasetCollection.__init__\u001B[1;34m(self, *datasets)\u001B[0m\n\u001B[0;32m    223\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cindex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m discrete:\n\u001B[1;32m--> 225\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    226\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMultisession implementation does not support discrete index yet.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    227\u001B[0m     )\n\u001B[0;32m    228\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dindex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: Multisession implementation does not support discrete index yet."
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
